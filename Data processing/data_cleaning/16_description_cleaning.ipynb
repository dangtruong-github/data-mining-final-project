{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3a0a8cf-8d36-49e6-891f-35e0b942a7c5",
   "metadata": {
    "id": "f3a0a8cf-8d36-49e6-891f-35e0b942a7c5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e7c1aa6-519c-46bc-96ef-007bbf1fdc40",
   "metadata": {
    "id": "9e7c1aa6-519c-46bc-96ef-007bbf1fdc40"
   },
   "outputs": [],
   "source": [
    "root = pd.read_csv('./15_clean_link_inside_description.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c8f2ae9-f729-4c5f-b69f-0d54b2e045b2",
   "metadata": {
    "id": "7c8f2ae9-f729-4c5f-b69f-0d54b2e045b2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df = root.drop(columns = ['depth', 'cover_img', 'recommended_stories', 'badges', 'Thời gian'])\n",
    "\n",
    "# Convert story_tags_list to array\n",
    "df['story_tags_list'] = df['story_tags_list'].apply(ast.literal_eval)\n",
    "\n",
    "# Deduplicate values in story_tags_list\n",
    "df['story_tags_list'] = df['story_tags_list'].apply(lambda x: np.unique(x))\n",
    "\n",
    "# Rearrange and rename indexes to code easier\n",
    "col_names = {'ID': 'id',\n",
    "             'title': 'title',\n",
    "             'Description': 'description',\n",
    "             'Lượt đọc': 'view',\n",
    "             'Lượt bình chọn': 'vote',\n",
    "             'Chương': 'chapter',\n",
    "             'story_tags_list': 'tag'}\n",
    "df = df.reindex(columns=['ID', 'title', 'Description', 'Lượt đọc', 'Lượt bình chọn', 'Chương', 'story_tags_list'])\n",
    "df = df.rename(columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96343809-bbcf-4213-b1e9-f48b740a6922",
   "metadata": {
    "id": "96343809-bbcf-4213-b1e9-f48b740a6922"
   },
   "outputs": [],
   "source": [
    "# Clean NaN\n",
    "df['title'].fillna(value='The', inplace=True)\n",
    "\n",
    "# Merge title and description into text\n",
    "df['title'] = df['title'] + ' ' + df['description']\n",
    "df = df.drop(columns=['description'])\n",
    "df = df.rename(columns={'title': 'text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a5f1004-e31f-40b8-a8df-8beb1999a0ce",
   "metadata": {
    "id": "1a5f1004-e31f-40b8-a8df-8beb1999a0ce",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cleaning function\n",
    "def clean(text):\n",
    "    if isinstance(text, str):\n",
    "        # unbold all character\n",
    "        text = unicodedata.normalize('NFKC', text)\n",
    "\n",
    "        # lowercase\n",
    "        text = text.lower()\n",
    "\n",
    "        # remove newline & punctuation\n",
    "        text = text.replace('\\n', ' ')\n",
    "        text = re.sub('[' + string.punctuation + ']', ' ', text)\n",
    "\n",
    "        # remove redundant space after above processes\n",
    "        text = ' '.join(text.split())\n",
    "\n",
    "        # aplly super regex (Vietnamese characters)\n",
    "        super_regex = r'[^ A-Za-z0-9\\u00C0\\u00C1\\u00C2\\u00C3\\u00C8\\u00C9\\u00CA\\u00CC\\u00CD\\u00D2\\u00D3\\u00D4\\u00D5\\u00D9\\u00DA\\u00DD\\u00E0\\u00E1\\u00E2\\u00E3\\u00E8\\u00E9\\u00EA\\u00EC\\u00ED\\u00F2\\u00F3\\u00F4\\u00F5\\u00F9\\u00FA\\u00FD\\u0102\\u0103\\u0110\\u0111\\u0128\\u0129\\u0168\\u0169\\u01A0\\u01A1\\u01AF\\u01B0\\u1EA0\\u1EA1\\u1EA2\\u1EA3\\u1EA4\\u1EA5\\u1EA6\\u1EA7\\u1EA8\\u1EA9\\u1EAA\\u1EAB\\u1EAC\\u1EAD\\u1EAE\\u1EAF\\u1EB0\\u1EB1\\u1EB2\\u1EB3\\u1EB4\\u1EB5\\u1EB6\\u1EB7\\u1EB8\\u1EB9\\u1EBA\\u1EBB\\u1EBC\\u1EBD\\u1EBE\\u1EBF\\u1EC0\\u1EC1\\u1EC2\\u1EC3\\u1EC4\\u1EC5\\u1EC6\\u1EC7\\u1EC8\\u1EC9\\u1ECA\\u1ECB\\u1ECC\\u1ECD\\u1ECE\\u1ECF\\u1ED0\\u1ED1\\u1ED2\\u1ED3\\u1ED4\\u1ED5\\u1ED6\\u1ED7\\u1ED8\\u1ED9\\u1EDA\\u1EDB\\u1EDC\\u1EDD\\u1EDE\\u1EDF\\u1EE0\\u1EE1\\u1EE2\\u1EE3\\u1EE4\\u1EE5\\u1EE6\\u1EE7\\u1EE8\\u1EE9\\u1EEA\\u1EEB\\u1EEC\\u1EED\\u1EEE\\u1EEF\\u1EF0\\u1EF1\\u1EF2\\u1EF3\\u1EF4\\u1EF5\\u1EF6\\u1EF7\\u1EF8\\u1EF9]'\n",
    "        text = re.sub(super_regex, '', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da6dbaa4-1e4f-4b11-b9b7-a55b4279381b",
   "metadata": {
    "id": "da6dbaa4-1e4f-4b11-b9b7-a55b4279381b"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Removing English stopwords\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_eng_stopwords\u001b[39m(text):\n\u001b[0;32m      5\u001b[0m     nlp \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "# Removing English stopwords\n",
    "import spacy\n",
    "\n",
    "def remove_eng_stopwords(text):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    filtered_words = [token.text for token in doc if not token.is_stop]\n",
    "    text = ' '.join(filtered_words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179f0e5e-1eb1-4ab9-a496-943e5a735041",
   "metadata": {
    "id": "179f0e5e-1eb1-4ab9-a496-943e5a735041"
   },
   "outputs": [],
   "source": [
    "# Removing Vietnamese stopwords\n",
    "def remove_vie_stopwords(text):\n",
    "    with open('vietnamese-stopwords.txt', 'r', encoding='utf-8') as file:\n",
    "        stopwords = [line.strip() for line in file]\n",
    "\n",
    "    # Create a regex pattern to match any word in stopwords\n",
    "    pattern = r'\\b(?:{})\\b'.format('|'.join(map(re.escape, stopwords)))\n",
    "    text = re.sub(pattern, '', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869f6102-3636-479d-ad7e-a3183ea08d6c",
   "metadata": {
    "id": "869f6102-3636-479d-ad7e-a3183ea08d6c"
   },
   "outputs": [],
   "source": [
    "# Set up for Vietnamese Segmentation\n",
    "from vws import RDRSegmenter, Tokenizer\n",
    "rdrsegment = RDRSegmenter.RDRSegmenter()\n",
    "tokenizer = Tokenizer.Tokenizer()\n",
    "\n",
    "# Segmentation\n",
    "def segment(text):\n",
    "    text = rdrsegment.segmentRawSentences(tokenizer, text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3402ec9c-c9ac-4640-9584-5323ebd96352",
   "metadata": {
    "id": "3402ec9c-c9ac-4640-9584-5323ebd96352",
    "outputId": "abb95bbd-ee8c-4cfc-d161-fccabf60f5be"
   },
   "outputs": [],
   "source": [
    "# English stemming\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "stemmer = nltk.PorterStemmer()\n",
    "\n",
    "# Stemming\n",
    "def stem(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    text = ' '.join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f6ddfc-9cad-4ccd-b3df-406fec5e2407",
   "metadata": {
    "id": "a1f6ddfc-9cad-4ccd-b3df-406fec5e2407"
   },
   "outputs": [],
   "source": [
    "# Apply everything\n",
    "df['text'] = df['text'].apply(clean)\n",
    "df['text'] = df['text'].apply(remove_eng_stopwords)\n",
    "df['text'] = df['text'].apply(remove_vie_stopwords)\n",
    "df['text'] = df['text'].apply(segment)\n",
    "df['text'] = df['text'].apply(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23a59b8-62ee-4d69-b79c-50d373a32c70",
   "metadata": {
    "id": "c23a59b8-62ee-4d69-b79c-50d373a32c70"
   },
   "outputs": [],
   "source": [
    "data = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc522c9e-0e27-45ca-8716-633a81bf04f4",
   "metadata": {
    "id": "bc522c9e-0e27-45ca-8716-633a81bf04f4"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "title_words = df['text'].str.split()\n",
    "word_counts = Counter([word for words in title_words for word in words])\n",
    "\n",
    "word_counts_dict = dict(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a7c718-99f2-476f-b4de-3ae36476cb8a",
   "metadata": {
    "id": "c3a7c718-99f2-476f-b4de-3ae36476cb8a"
   },
   "outputs": [],
   "source": [
    "sorted_word_count_dict = sorted(word_counts_dict.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666c1073-4b52-438a-a4b7-45d0c02610b1",
   "metadata": {
    "id": "666c1073-4b52-438a-a4b7-45d0c02610b1"
   },
   "outputs": [],
   "source": [
    "# Specify the file path\n",
    "file_path = 'raw_dictionary.txt'\n",
    "\n",
    "# Open the file in write mode\n",
    "with open(file_path, 'w', encoding='utf-8') as file:\n",
    "    # Write each key-value pair with a newline after each pair\n",
    "    for key, value in dict(sorted_word_count_dict).items():\n",
    "        file.write(f\"{key}: {value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e6bfca-7faf-44e5-964c-3689247c164f",
   "metadata": {
    "id": "05e6bfca-7faf-44e5-964c-3689247c164f"
   },
   "outputs": [],
   "source": [
    "df.to_csv('./16a_description_cleaned.csv', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2802a4c4-9870-4e60-b739-15e3d7f760c9",
   "metadata": {
    "id": "2802a4c4-9870-4e60-b739-15e3d7f760c9"
   },
   "outputs": [],
   "source": [
    "new_data = pd.read_csv('./16a_description_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be88c25b-14b8-41b9-a44b-5ee9962350eb",
   "metadata": {
    "id": "be88c25b-14b8-41b9-a44b-5ee9962350eb",
    "outputId": "37a6a6bf-d06e-4ff8-c392-cd70494dc1d2"
   },
   "outputs": [],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa60b920-0bc9-48e0-85e0-e002a6a90ceb",
   "metadata": {
    "id": "aa60b920-0bc9-48e0-85e0-e002a6a90ceb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd73674",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
